---
title: "Meta-learning three-factor learning rules for reward-driven training of RNNs"
excerpt: >-
  Reinforcement learning plasticity rules for reinforcement training of RNNs <br/> started as a postdoc independently (May 2025)
  <br/><img src="/images/meta_training.png" alt="Reward-driven training of RNNs-Dimitra Maoutsa" width="260" style="display:block; margin:0 auto;" />
collection: portfolio
---


We have devised a method for discovering plasticity rules for reward-driven training of recurrent networks.

<img src='/images/meta_training.png' alt="Discovering reward-driven training rules for reinforcement training of RNNs - Dimitra Maoutsa" style="max-width:600px; width:60%;" >

Here is a very coarse pre-print sketching out the ideas **submitted at NeurIPS 2025** (without results) ([see here](https://openreview.net/forum?id=KkOMqJQiWU)) to test for interest (and ensure that when I present it as a poster in upcomming conferences I will have proof of the origin of the ideas)  and **pre-printed on 13th of August 2025** [here](https://openreview.net/forum?id=V13CdTeMsT). 

Presented as a poster at: **Champalimaud Neuro-cybernetics Symposium - Oct 2025** ([see here for more info](https://dimitra-maoutsa.github.io/M-Dims-Blog/posts/untitled2.html))

Upcomming presentations: 
- **NeurIPS 2025 - NeurReps workshop**
- **NeurIPS 2025 - WiML workshop**

If someone happens to claim that this is work/ideas/dreams that belong to my previous lab, please read the emial exchange here that explicitly states that I am free to pursue this project because we never discussed anything other than me proposing to use a three-factor rule [here](https://dimitra-maoutsa.github.io/M-Dims-Blog/posts/Three_factor_rules.html).
